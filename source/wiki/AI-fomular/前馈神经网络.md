---
title: 前馈神经网络
date: 2026-02-05 12:00:00
---

这里才是正文...

# 前馈神经网络 (FFN) 

我们继续使用 **"Thinking"** 的例子。
FFN 的核心公式是：
$$\text{FFN}(x) = \text{ReLU}(xW_1 + b_1)W_2 + b_2$$

## 场景设定与准备

为了方便口算，我们将上一章 Attention 算出的结果 $[13.6, 23.6]$ 简化取整。

* **输入向量 ($x$)**：`[10, 20]`
    * 这是 Attention 层的输出，维度 $d_{model} = 2$。
* **目标**：
    1. 先**升维**（把 2 维变成 4 维），把特征拆解开。
    2. 通过 **ReLU** 过滤负数。
    3. 再**降维**（把 4 维变回 2 维），整合结果。

我们需要预设两组权重矩阵（在真实模型中，这些是训练出来的）：

* **第一层参数 ($W_1, b_1$) - 负责升维**：
    * $W_1$ ($2 \times 4$ 矩阵)
    * $b_1$ ($1 \times 4$ 向量)
* **第二层参数 ($W_2, b_2$) - 负责降维**：
    * $W_2$ ($4 \times 2$ 矩阵)
    * $b_2$ ($1 \times 2$ 向量)

---

## 1. 第一步：线性变换与升维 ($xW_1 + b_1$)

FFN 的第一层通常很宽（Wide）。我们假设 $W_1$ 和 $b_1$ 如下：

$$
W_1 = \begin{bmatrix}
1 & -1 & 2 & 0 \\
0 & 2 & -1 & 1
\end{bmatrix}, \quad
b_1 = [0, \quad 0, \quad -5, \quad 0]
$$

**计算过程：**

$$
\begin{aligned}
Z &= x \cdot W_1 + b_1 \\
&= [10, 20] \cdot \begin{bmatrix} 1 & -1 & 2 & 0 \\ 0 & 2 & -1 & 1 \end{bmatrix} + [0, 0, -5, 0] \\
\end{aligned}
$$

**逐维度口算：**
* **第1维**：$10\times1 + 20\times0 + 0 = \mathbf{10}$
* **第2维**：$10\times(-1) + 20\times2 + 0 = -10 + 40 = \mathbf{30}$
* **第3维**：$10\times2 + 20\times(-1) + (-5) = 20 - 20 - 5 = \mathbf{-5}$  **(注意这个负数!)**
* **第4维**：$10\times0 + 20\times1 + 0 = \mathbf{20}$

**中间结果 ($Z$)：**
$$[10, \quad 30, \quad -5, \quad 20]$$

> **💡 意义**：原本 2 个维度的信息，被拆解到了 4 个维度空间里，就像把一束白光用三棱镜分解成七色光。

---

## 2. 第二步：非线性激活 (ReLU)

公式：$\text{ReLU}(z) = \max(0, z)$
这一步非常简单粗暴：**所有负数直接归零，正数保持不变。**

$$
\begin{aligned}
H &= \text{ReLU}([10, \quad 30, \quad \mathbf{-5}, \quad 20]) \\
&= [10, \quad 30, \quad \mathbf{0}, \quad 20]
\end{aligned}
$$

> **💡 意义**：
> * 注意那个 **-5 变成了 0**。
> * 这就是**“筛选”**。模型认为第 3 个维度的特征（可能是某种噪音或无关信息）对当前任务没有帮助，所以直接“关掉”了神经元。

---

## 3. 第三步：线性变换与降维 ($HW_2 + b_2$)

现在我们要把这个 4 维向量压回 2 维，方便传给下一层。
假设 $W_2$ 和 $b_2$ 如下：

$$
W_2 = \begin{bmatrix}
1 & 0 \\
1 & 1 \\
0 & 0 \\
2 & 1
\end{bmatrix}, \quad
b_2 = [1, \quad 1]
$$

**计算过程：**

$$
\begin{aligned}
\text{Output} &= H \cdot W_2 + b_2 \\
&= [10, 30, 0, 20] \cdot \begin{bmatrix} 1 & 0 \\ 1 & 1 \\ 0 & 0 \\ 2 & 1 \end{bmatrix} + [1, 1]
\end{aligned}
$$

**逐维度口算：**
* **第1维**：
    $(10\times1) + (30\times1) + (0\times0) + (20\times2) + 1$
    $= 10 + 30 + 0 + 40 + 1 = \mathbf{81}$

* **第2维**：
    $(10\times0) + (30\times1) + (0\times0) + (20\times1) + 1$
    $= 0 + 30 + 0 + 20 + 1 = \mathbf{51}$

---

## 4. 最终结果对比

$$
\text{FFN Output} = [\mathbf{81}, \mathbf{51}]
$$

让我们回顾一下全过程的变化：

| 阶段 | 向量值 | 维度 | 状态描述 |
| :--- | :--- | :--- | :--- |
| **FFN 输入** | `[10, 20]` | 2维 | 刚开完会（Attention），收集了信息，但比较杂。 |
| **中间层 (ReLU前)** | `[10, 30, -5, 20]` | **4维** | 大脑风暴，把想法发散开，产生了很多念头。 |
| **激活后 (ReLU后)** | `[10, 30, 0, 20]` | **4维** | 否定了不靠谱的念头（-5 被归零）。 |
| **FFN 输出** | `[81, 51]` | 2维 | 总结陈词，形成经过深思熟虑的新观点。 |